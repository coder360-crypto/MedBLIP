{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation\n",
        "Vision-Language Pre-training (VLP) has advanced the performance for many vision-language tasks. However, most existing pre-trained models only excel in either understanding-based tasks or generation-based tasks. Furthermore, performance improvement has been largely achieved by scaling up the dataset with noisy image-text pairs collected from the web, which is a suboptimal source of supervision. In this paper, we propose BLIP, a new VLP framework which transfers flexibly to both vision-language understanding and generation tasks. BLIP effectively utilizes the noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. We achieve state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval (+2.7% in average recall@1), image captioning (+2.8% in CIDEr), and VQA (+1.6% in VQA score). BLIP also demonstrates strong generalization ability when directly transferred to videolanguage tasks in a zero-shot manner. Code, models, and datasets are released.\n",
        "* Paper: https://arxiv.org/abs/2201.12086"
      ],
      "metadata": {
        "id": "_6UXdG9wdrQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Radiology Objects in COntext (ROCO): A Multimodal Image Dataset\n",
        "Radiology Objects in COntext (ROCO) dataset, a large-scale medical and multimodal imaging dataset. The listed images are from publications available on the PubMed Central Open Access FTP mirror, which were automatically detected as non-compound and either radiology or non-radiology. Each image is distributed as a download link, together with its caption. Additionally, keywords extracted from the image caption, as well as the corresponding UMLS Semantic Types (SemTypes) and UMLS Concept Unique Identifiers (CUIs) are available. The dataset could be used to build generative models for image captioning, classification models for image categorization and tagging or content-based image retrieval systems.\n",
        "\n",
        "* Dataset: https://github.com/razorx89/roco-dataset\n"
      ],
      "metadata": {
        "id": "1ndN-tp4drQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Caption Generation from Chest X-Ray Images:\n",
        "![](https://i.ibb.co/G9bd0bg/chest-Xray.png)"
      ],
      "metadata": {
        "id": "eL3rj1c9drQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Task : Fine tune Captioning model with a custom dataset using the following transformers to generate description of a chest x-ray image.\n",
        "Base Model: The base transformers models to be used for fine tuning :\n",
        "\n",
        "Salesforce/blip-image-captioning-large\n",
        "\n",
        "Dataset : Radiology Objects in COntext (ROCO): A Multimodal Image Dataset\n",
        "\n",
        "Link : https://www.kaggle.com/datasets/virajbagal/roco-dataset\n"
      ],
      "metadata": {
        "id": "VFFD_RRadrQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation and Dataloader"
      ],
      "metadata": {
        "id": "WlrXDoa3euUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install latest version of the library\n",
        "!pip install -q datasets==2.13.1 nltk"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T08:32:47.655091Z",
          "iopub.execute_input": "2023-08-28T08:32:47.655622Z",
          "iopub.status.idle": "2023-08-28T08:33:03.024018Z",
          "shell.execute_reply.started": "2023-08-28T08:32:47.655586Z",
          "shell.execute_reply": "2023-08-28T08:33:03.022724Z"
        },
        "trusted": true,
        "id": "NgoNjd81drQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import important libraries\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import transformers\n",
        "from transformers import BlipProcessor, BlipForImageTextRetrieval,BlipForConditionalGeneration, AutoProcessor\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import Resize\n",
        "import os\n",
        "\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import shutil\n",
        "import json\n",
        "from PIL import Image\n",
        "import requests\n",
        "from matplotlib import pyplot as plt\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-08-28T08:33:03.027951Z",
          "iopub.execute_input": "2023-08-28T08:33:03.028262Z",
          "iopub.status.idle": "2023-08-28T08:33:15.376356Z",
          "shell.execute_reply.started": "2023-08-28T08:33:03.028233Z",
          "shell.execute_reply": "2023-08-28T08:33:15.375306Z"
        },
        "trusted": true,
        "id": "-vlTsQYXdrQU",
        "outputId": "0079a0d2-b71c-447f-8f14-357d246eea54"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV dataset from Pandas\n",
        "df_train = pd.read_csv('/kaggle/input/roco-dataset/all_data/train/radiologytraindata.csv', delimiter=',') #, nrows = nRowsRead\n",
        "df_train.dataframeName = 'radiologytestdata.csv'\n",
        "nRow, nCol = df_train.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T08:33:15.377982Z",
          "iopub.execute_input": "2023-08-28T08:33:15.378343Z",
          "iopub.status.idle": "2023-08-28T08:33:15.815212Z",
          "shell.execute_reply.started": "2023-08-28T08:33:15.378307Z",
          "shell.execute_reply": "2023-08-28T08:33:15.813266Z"
        },
        "trusted": true,
        "id": "Vivu2XDMdrQV",
        "outputId": "76b0a72a-e48b-44d8-d107-63a401641dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "There are 65450 rows and 3 columns\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display first 5 columns of dataframe\n",
        "df_train.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T08:33:15.818129Z",
          "iopub.execute_input": "2023-08-28T08:33:15.818483Z",
          "iopub.status.idle": "2023-08-28T08:33:15.834785Z",
          "shell.execute_reply.started": "2023-08-28T08:33:15.818446Z",
          "shell.execute_reply": "2023-08-28T08:33:15.833870Z"
        },
        "trusted": true,
        "id": "1ZJTe2lIdrQW",
        "outputId": "2086d907-7c02-4c3a-dd1a-2bd59fb8ae8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "           id                                    name  \\\n0  ROCO_00002          PMC4083729_AMHSR-4-14-g002.jpg   \n1  ROCO_00003       PMC2837471_IJD2009-150251.001.jpg   \n2  ROCO_00004  PMC2505281_11999_2007_30_Fig6_HTML.jpg   \n3  ROCO_00005       PMC3745845_IJD2013-683423.005.jpg   \n4  ROCO_00007   PMC4917066_amjcaserep-17-301-g001.jpg   \n\n                                             caption  \n0   Computed tomography scan in axial view showin...  \n1   Bacterial contamination occurred after comple...  \n2   The patient had residual paralysis of the han...  \n3    Panoramic radiograph after immediate loading.\\n  \n4   Plain abdomen x-ray: Multiple air levels at t...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ROCO_00002</td>\n      <td>PMC4083729_AMHSR-4-14-g002.jpg</td>\n      <td>Computed tomography scan in axial view showin...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ROCO_00003</td>\n      <td>PMC2837471_IJD2009-150251.001.jpg</td>\n      <td>Bacterial contamination occurred after comple...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ROCO_00004</td>\n      <td>PMC2505281_11999_2007_30_Fig6_HTML.jpg</td>\n      <td>The patient had residual paralysis of the han...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ROCO_00005</td>\n      <td>PMC3745845_IJD2013-683423.005.jpg</td>\n      <td>Panoramic radiograph after immediate loading.\\n</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ROCO_00007</td>\n      <td>PMC4917066_amjcaserep-17-301-g001.jpg</td>\n      <td>Plain abdomen x-ray: Multiple air levels at t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Search those captiones which contains \"chest x-ray\" words\n",
        "mask = df_train['caption'].str.contains('chest x-ray', case=False)\n",
        "filtered_df = df_train[mask]\n",
        "filtered_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T08:33:15.836406Z",
          "iopub.execute_input": "2023-08-28T08:33:15.836767Z",
          "iopub.status.idle": "2023-08-28T08:33:15.993587Z",
          "shell.execute_reply.started": "2023-08-28T08:33:15.836735Z",
          "shell.execute_reply": "2023-08-28T08:33:15.992568Z"
        },
        "trusted": true,
        "id": "Wt6d_qhodrQX",
        "outputId": "49eb91a4-ae89-4e6a-a06c-2baa39f669ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "             id                                        name  \\\n69   ROCO_00087            PMC5144533_IJCCM-20-677-g002.jpg   \n141  ROCO_00172               PMC4863054_ir-14-187-g002.jpg   \n180  ROCO_00232            PMC4093973_IJCIIS-4-186-g001.jpg   \n215  ROCO_00274  PMC5616218_cureus-0009-00000001523-i01.jpg   \n307  ROCO_00383                          PMC5018069_gr1.jpg   \n\n                                               caption  \n69    Chest X-ray, which confirmed the position of ...  \n141   Chest X-ray findings. Chest radiograph reveal...  \n180   Chest X-ray, PA, showing the position of the ...  \n215    Chest x-ray showing right-sided pneumothorax.\\n  \n307   Chest X-ray on the day of admission showing d...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>69</th>\n      <td>ROCO_00087</td>\n      <td>PMC5144533_IJCCM-20-677-g002.jpg</td>\n      <td>Chest X-ray, which confirmed the position of ...</td>\n    </tr>\n    <tr>\n      <th>141</th>\n      <td>ROCO_00172</td>\n      <td>PMC4863054_ir-14-187-g002.jpg</td>\n      <td>Chest X-ray findings. Chest radiograph reveal...</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>ROCO_00232</td>\n      <td>PMC4093973_IJCIIS-4-186-g001.jpg</td>\n      <td>Chest X-ray, PA, showing the position of the ...</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>ROCO_00274</td>\n      <td>PMC5616218_cureus-0009-00000001523-i01.jpg</td>\n      <td>Chest x-ray showing right-sided pneumothorax.\\n</td>\n    </tr>\n    <tr>\n      <th>307</th>\n      <td>ROCO_00383</td>\n      <td>PMC5018069_gr1.jpg</td>\n      <td>Chest X-ray on the day of admission showing d...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create \"images\" column to create full path for images\n",
        "filtered_df['images'] = \"/kaggle/input/roco-dataset/all_data/train/radiology/images/\" + filtered_df['name']\n",
        "filtered_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T08:33:15.995321Z",
          "iopub.execute_input": "2023-08-28T08:33:15.995685Z",
          "iopub.status.idle": "2023-08-28T08:33:16.008545Z",
          "shell.execute_reply.started": "2023-08-28T08:33:15.995651Z",
          "shell.execute_reply": "2023-08-28T08:33:16.007317Z"
        },
        "trusted": true,
        "id": "skMMrB3_drQY",
        "outputId": "4beb0d5c-bcb9-426c-df41-3110f91bb355"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_28/1067852196.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  filtered_df['images'] = \"/kaggle/input/roco-dataset/all_data/train/radiology/images/\" + filtered_df['name']\n",
          "output_type": "stream"
        },
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "             id                                        name  \\\n69   ROCO_00087            PMC5144533_IJCCM-20-677-g002.jpg   \n141  ROCO_00172               PMC4863054_ir-14-187-g002.jpg   \n180  ROCO_00232            PMC4093973_IJCIIS-4-186-g001.jpg   \n215  ROCO_00274  PMC5616218_cureus-0009-00000001523-i01.jpg   \n307  ROCO_00383                          PMC5018069_gr1.jpg   \n\n                                               caption  \\\n69    Chest X-ray, which confirmed the position of ...   \n141   Chest X-ray findings. Chest radiograph reveal...   \n180   Chest X-ray, PA, showing the position of the ...   \n215    Chest x-ray showing right-sided pneumothorax.\\n   \n307   Chest X-ray on the day of admission showing d...   \n\n                                                images  \n69   /kaggle/input/roco-dataset/all_data/train/radi...  \n141  /kaggle/input/roco-dataset/all_data/train/radi...  \n180  /kaggle/input/roco-dataset/all_data/train/radi...  \n215  /kaggle/input/roco-dataset/all_data/train/radi...  \n307  /kaggle/input/roco-dataset/all_data/train/radi...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>caption</th>\n      <th>images</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>69</th>\n      <td>ROCO_00087</td>\n      <td>PMC5144533_IJCCM-20-677-g002.jpg</td>\n      <td>Chest X-ray, which confirmed the position of ...</td>\n      <td>/kaggle/input/roco-dataset/all_data/train/radi...</td>\n    </tr>\n    <tr>\n      <th>141</th>\n      <td>ROCO_00172</td>\n      <td>PMC4863054_ir-14-187-g002.jpg</td>\n      <td>Chest X-ray findings. Chest radiograph reveal...</td>\n      <td>/kaggle/input/roco-dataset/all_data/train/radi...</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>ROCO_00232</td>\n      <td>PMC4093973_IJCIIS-4-186-g001.jpg</td>\n      <td>Chest X-ray, PA, showing the position of the ...</td>\n      <td>/kaggle/input/roco-dataset/all_data/train/radi...</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>ROCO_00274</td>\n      <td>PMC5616218_cureus-0009-00000001523-i01.jpg</td>\n      <td>Chest x-ray showing right-sided pneumothorax.\\n</td>\n      <td>/kaggle/input/roco-dataset/all_data/train/radi...</td>\n    </tr>\n    <tr>\n      <th>307</th>\n      <td>ROCO_00383</td>\n      <td>PMC5018069_gr1.jpg</td>\n      <td>Chest X-ray on the day of admission showing d...</td>\n      <td>/kaggle/input/roco-dataset/all_data/train/radi...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new directory for training images\n",
        "folder_path = \"/kaggle/working/train\"\n",
        "if not os.path.exists(folder_path):\n",
        "    os.mkdir(folder_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T08:33:16.010699Z",
          "iopub.execute_input": "2023-08-28T08:33:16.011139Z",
          "iopub.status.idle": "2023-08-28T08:33:16.017466Z",
          "shell.execute_reply.started": "2023-08-28T08:33:16.011108Z",
          "shell.execute_reply": "2023-08-28T08:33:16.016362Z"
        },
        "trusted": true,
        "id": "xUxp--sNdrQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the DataFrame and move the files to the destination folder\n",
        "for index, row in filtered_df.iterrows():\n",
        "    source_file = row[\"images\"]\n",
        "    file_name = os.path.basename(source_file)\n",
        "    destination_file = os.path.join(folder_path, file_name)\n",
        "\n",
        "    # Use shutil.move() to move the file\n",
        "    shutil.copy(source_file, folder_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T08:33:16.019179Z",
          "iopub.execute_input": "2023-08-28T08:33:16.019974Z",
          "iopub.status.idle": "2023-08-28T08:33:24.169654Z",
          "shell.execute_reply.started": "2023-08-28T08:33:16.019941Z",
          "shell.execute_reply": "2023-08-28T08:33:24.168676Z"
        },
        "trusted": true,
        "id": "BMM7afYPdrQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete extra column from the dataframe\n",
        "filtered_df = filtered_df.drop(columns=[\"images\", \"id\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T08:33:24.170878Z",
          "iopub.execute_input": "2023-08-28T08:33:24.171257Z",
          "iopub.status.idle": "2023-08-28T08:33:24.177496Z",
          "shell.execute_reply.started": "2023-08-28T08:33:24.171224Z",
          "shell.execute_reply": "2023-08-28T08:33:24.176249Z"
        },
        "trusted": true,
        "id": "tLsK0hsudrQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dataframe to json format\n",
        "captions = filtered_df.apply(lambda row: {\"file_name\": row[\"name\"], \"text\": row[\"caption\"]}, axis=1).tolist()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T08:33:24.183477Z",
          "iopub.execute_input": "2023-08-28T08:33:24.184437Z",
          "iopub.status.idle": "2023-08-28T08:33:24.219016Z",
          "shell.execute_reply.started": "2023-08-28T08:33:24.184401Z",
          "shell.execute_reply": "2023-08-28T08:33:24.218195Z"
        },
        "trusted": true,
        "id": "f6eglcwHdrQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save data to json file\n",
        "with open(folder_path + \"/metadata.jsonl\", 'w') as f:\n",
        "    for item in captions:\n",
        "        f.write(json.dumps(item))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T08:33:24.221498Z",
          "iopub.execute_input": "2023-08-28T08:33:24.222308Z",
          "iopub.status.idle": "2023-08-28T08:33:24.239087Z",
          "shell.execute_reply.started": "2023-08-28T08:33:24.222276Z",
          "shell.execute_reply": "2023-08-28T08:33:24.238269Z"
        },
        "trusted": true,
        "id": "_tcFwg6HdrQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset for training\n",
        "dataset = load_dataset(\"imagefolder\", data_dir=folder_path, split=\"train\")\n",
        "dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T08:33:24.240386Z",
          "iopub.execute_input": "2023-08-28T08:33:24.240775Z",
          "iopub.status.idle": "2023-08-28T08:33:27.677794Z",
          "shell.execute_reply.started": "2023-08-28T08:33:24.240743Z",
          "shell.execute_reply": "2023-08-28T08:33:27.676776Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "5d3bfb425eec45fc905779e734cd1606",
            "8aa4c1faaae04f638203b2cce66ce67c",
            "3bb063426e9f458ab87d1101210d5390",
            "e577ef42dba147268e21326dc71215dd",
            ""
          ]
        },
        "id": "eiXfH0Q-drQd",
        "outputId": "110c7f85-5c9d-4519-d09f-f7b5a4c25671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Resolving data files:   0%|          | 0/1736 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d3bfb425eec45fc905779e734cd1606"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Downloading and preparing dataset imagefolder/default to /root/.cache/huggingface/datasets/imagefolder/default-81adc05ab31ba1cd/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data files:   0%|          | 0/1736 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8aa4c1faaae04f638203b2cce66ce67c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data files: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bb063426e9f458ab87d1101210d5390"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Extracting data files: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e577ef42dba147268e21326dc71215dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Dataset imagefolder downloaded and prepared to /root/.cache/huggingface/datasets/imagefolder/default-81adc05ab31ba1cd/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n",
          "output_type": "stream"
        },
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['image', 'text'],\n    num_rows: 1735\n})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create class for training\n",
        "\n",
        "class ImageCaptioningDataset(Dataset):\n",
        "    def __init__(self, dataset, processor, image_size=(224, 224)):\n",
        "        self.dataset = dataset\n",
        "        self.processor = processor\n",
        "        self.image_size = image_size\n",
        "        self.resize_transform = Resize(image_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.dataset[idx]\n",
        "        encoding = self.processor(images=item[\"image\"], text=item[\"text\"], padding=\"max_length\", return_tensors=\"pt\")\n",
        "        # remove batch dimension\n",
        "        encoding = {k:v.squeeze() for k,v in encoding.items()}\n",
        "        return encoding"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T08:33:27.679266Z",
          "iopub.execute_input": "2023-08-28T08:33:27.680093Z",
          "iopub.status.idle": "2023-08-28T08:33:27.688501Z",
          "shell.execute_reply.started": "2023-08-28T08:33:27.680056Z",
          "shell.execute_reply": "2023-08-28T08:33:27.687020Z"
        },
        "trusted": true,
        "id": "Y_FZ36VCdrQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build and Train"
      ],
      "metadata": {
        "id": "zo0sQCyveo_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model from Huggingface Transformer library\n",
        "processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T08:33:27.689979Z",
          "iopub.execute_input": "2023-08-28T08:33:27.690319Z",
          "iopub.status.idle": "2023-08-28T08:34:01.738529Z",
          "shell.execute_reply.started": "2023-08-28T08:33:27.690286Z",
          "shell.execute_reply": "2023-08-28T08:34:01.737495Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "be4726fd72544d9482ca81c6cf2812b8",
            "0375d4ebc9b1458fb50a593e0bd28443",
            "82210f34aa4e4201b4a25f8551e023fb",
            "bcd0fc8e0a5e436ba609502cdf90ab26",
            "4f8aaa11a90749a6a3b782e5bcf35932",
            "a5a6c88644ab4f7bbb9f466ad7e1be2a",
            "cef83497b2b4494f826430499c39bde3"
          ]
        },
        "id": "of546RlRdrQe",
        "outputId": "7eda21db-8475-4543-8ec6-80ab7cbdb483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)rocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be4726fd72544d9482ca81c6cf2812b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0375d4ebc9b1458fb50a593e0bd28443"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82210f34aa4e4201b4a25f8551e023fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcd0fc8e0a5e436ba609502cdf90ab26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f8aaa11a90749a6a3b782e5bcf35932"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5a6c88644ab4f7bbb9f466ad7e1be2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cef83497b2b4494f826430499c39bde3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset for training\n",
        "image_size = (224, 224)\n",
        "train_dataset = ImageCaptioningDataset(dataset, processor, image_size)\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=2)\n",
        "train_dataloader"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T08:34:01.739931Z",
          "iopub.execute_input": "2023-08-28T08:34:01.740387Z",
          "iopub.status.idle": "2023-08-28T08:34:01.748707Z",
          "shell.execute_reply.started": "2023-08-28T08:34:01.740353Z",
          "shell.execute_reply": "2023-08-28T08:34:01.747769Z"
        },
        "trusted": true,
        "id": "nIv-JgYvdrQf",
        "outputId": "df9d1cd4-b762-4733-f749-250a881ac6dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<torch.utils.data.dataloader.DataLoader at 0x7fc065e92800>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T08:34:01.750101Z",
          "iopub.execute_input": "2023-08-28T08:34:01.750667Z",
          "iopub.status.idle": "2023-08-28T08:34:06.567072Z",
          "shell.execute_reply.started": "2023-08-28T08:34:01.750635Z",
          "shell.execute_reply": "2023-08-28T08:34:06.565986Z"
        },
        "trusted": true,
        "id": "u5YOxtHXdrQf",
        "outputId": "536ee222-403b-4e43-e22d-3ac685c5fbc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "BlipForConditionalGeneration(\n  (vision_model): BlipVisionModel(\n    (embeddings): BlipVisionEmbeddings(\n      (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n    )\n    (encoder): BlipEncoder(\n      (layers): ModuleList(\n        (0-11): 12 x BlipEncoderLayer(\n          (self_attn): BlipAttention(\n            (dropout): Dropout(p=0.0, inplace=False)\n            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n            (projection): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): BlipMLP(\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (text_decoder): BlipTextLMHeadModel(\n    (bert): BlipTextModel(\n      (embeddings): BlipTextEmbeddings(\n        (word_embeddings): Embedding(30524, 768, padding_idx=0)\n        (position_embeddings): Embedding(512, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (encoder): BlipTextEncoder(\n        (layer): ModuleList(\n          (0-11): 12 x BlipTextLayer(\n            (attention): BlipTextAttention(\n              (self): BlipTextSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n              (output): BlipTextSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (crossattention): BlipTextAttention(\n              (self): BlipTextSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n              (output): BlipTextSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (intermediate): BlipTextIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BlipTextOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n    )\n    (cls): BlipTextOnlyMLMHead(\n      (predictions): BlipTextLMPredictionHead(\n        (transform): BlipTextPredictionHeadTransform(\n          (dense): Linear(in_features=768, out_features=768, bias=True)\n          (transform_act_fn): GELUActivation()\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (decoder): Linear(in_features=768, out_features=30524, bias=True)\n      )\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Start training\n",
        "for epoch in range(5):\n",
        "  print(\"Epoch:\", epoch)\n",
        "  for idx, batch in enumerate(train_dataloader):\n",
        "    input_ids = batch.pop(\"input_ids\").to(device)\n",
        "    pixel_values = batch.pop(\"pixel_values\").to(device)\n",
        "\n",
        "    outputs = model(input_ids=input_ids,\n",
        "                    pixel_values=pixel_values,\n",
        "                    labels=input_ids)\n",
        "\n",
        "    loss = outputs.loss\n",
        "\n",
        "    #print(\"Loss:\", loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  print(\"Loss:\", loss.item())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T08:34:06.568455Z",
          "iopub.execute_input": "2023-08-28T08:34:06.568900Z",
          "iopub.status.idle": "2023-08-28T09:00:51.361140Z",
          "shell.execute_reply.started": "2023-08-28T08:34:06.568865Z",
          "shell.execute_reply": "2023-08-28T09:00:51.360065Z"
        },
        "trusted": true,
        "id": "hZ6_u1ncdrQg",
        "outputId": "54dec434-f7ce-4d58-a281-95616db2738b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch: 0\nLoss: 1.4102307558059692\nEpoch: 1\nLoss: 1.4249589443206787\nEpoch: 2\nLoss: 1.4672106504440308\nEpoch: 3\nLoss: 1.424098014831543\nEpoch: 4\nLoss: 1.413473129272461\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Create save model path and save the trained model\n",
        "saved_folder_path = \"/kaggle/working/saved_model\"\n",
        "if not os.path.exists(saved_folder_path):\n",
        "    os.mkdir(saved_folder_path)\n",
        "\n",
        "model.save_pretrained(saved_folder_path)\n",
        "processor.save_pretrained(saved_folder_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T09:00:51.362805Z",
          "iopub.execute_input": "2023-08-28T09:00:51.363629Z",
          "iopub.status.idle": "2023-08-28T09:00:52.785622Z",
          "shell.execute_reply.started": "2023-08-28T09:00:51.363592Z",
          "shell.execute_reply": "2023-08-28T09:00:52.784605Z"
        },
        "trusted": true,
        "id": "cExiaEW6drQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Load the trained model\n",
        "load_model = BlipForConditionalGeneration.from_pretrained(saved_folder_path)\n",
        "load_processor = AutoProcessor.from_pretrained(saved_folder_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T09:00:52.786992Z",
          "iopub.execute_input": "2023-08-28T09:00:52.787433Z",
          "iopub.status.idle": "2023-08-28T09:00:55.750736Z",
          "shell.execute_reply.started": "2023-08-28T09:00:52.787399Z",
          "shell.execute_reply": "2023-08-28T09:00:55.749691Z"
        },
        "trusted": true,
        "id": "fxpUEeg-drQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"/kaggle/input/roco-dataset/all_data/test/radiology/images/PMC1208923_1476-7120-3-19-3.jpg\"\n",
        "\n",
        "image = Image.open(url)\n",
        "\n",
        "\n",
        "# # prepare image for the model\n",
        "inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
        "pixel_values = inputs.pixel_values\n",
        "\n",
        "generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n",
        "generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "print(generated_caption)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T09:00:55.752233Z",
          "iopub.execute_input": "2023-08-28T09:00:55.752572Z",
          "iopub.status.idle": "2023-08-28T09:00:55.758961Z",
          "shell.execute_reply.started": "2023-08-28T09:00:55.752538Z",
          "shell.execute_reply": "2023-08-28T09:00:55.757944Z"
        },
        "trusted": true,
        "id": "OMmQIpZpdrQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Test Dataset\n",
        "\n",
        "df_test = pd.read_csv('/kaggle/input/roco-dataset/all_data/test/radiology/testdata.csv', delimiter=',')\n",
        "mask = df_test['caption'].str.contains('chest x-ray', case=False)\n",
        "filtered_df = df_test[mask]\n",
        "filtered_df.head()\n",
        "filtered_df['images'] = \"/kaggle/input/roco-dataset/all_data/test/radiology/images/\" + filtered_df['name']\n",
        "filtered_df.head()\n",
        "folder_path = \"/kaggle/working/test\"\n",
        "if not os.path.exists(folder_path):\n",
        "    os.mkdir(folder_path)\n",
        "# Iterate through the DataFrame and move the files to the destination folder\n",
        "for index, row in filtered_df.iterrows():\n",
        "    source_file = row[\"images\"]\n",
        "    file_name = os.path.basename(source_file)\n",
        "    destination_file = os.path.join(folder_path, file_name)\n",
        "\n",
        "    # Use shutil.move() to move the file\n",
        "    shutil.copy(source_file, folder_path)\n",
        "\n",
        "filtered_df = filtered_df.drop(columns=[\"images\", \"id\"])\n",
        "captions = filtered_df.apply(lambda row: {\"file_name\": row[\"name\"], \"text\": row[\"caption\"]}, axis=1).tolist()\n",
        "# add metadata.jsonl file to this folder\n",
        "with open(folder_path + \"/metadata.jsonl\", 'w') as f:\n",
        "    for item in captions:\n",
        "        f.write(json.dumps(item))\n",
        "test_dataset = load_dataset(\"imagefolder\", data_dir=folder_path, split=\"train\")\n",
        "test_dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T09:00:55.760395Z",
          "iopub.execute_input": "2023-08-28T09:00:55.760880Z",
          "iopub.status.idle": "2023-08-28T09:00:58.733165Z",
          "shell.execute_reply.started": "2023-08-28T09:00:55.760847Z",
          "shell.execute_reply": "2023-08-28T09:00:58.732214Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "959c31a1d4924afaa994495d32e5cdd5",
            "50d16bbc62284b9f98059f0fd2657a1e",
            "82815d392a8d4d4f8697e201eeed1382",
            "2cd30e05110e44a7ad2134eae6c0588b",
            ""
          ]
        },
        "id": "qMdA6xc9drQj",
        "outputId": "0dc16013-0b7f-4167-cb2b-3cc3a3d73442"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_28/3653442878.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  filtered_df['images'] = \"/kaggle/input/roco-dataset/all_data/test/radiology/images/\" + filtered_df['name']\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Resolving data files:   0%|          | 0/200 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "959c31a1d4924afaa994495d32e5cdd5"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Downloading and preparing dataset imagefolder/default to /root/.cache/huggingface/datasets/imagefolder/default-bf4a63f19f0a675a/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data files:   0%|          | 0/200 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50d16bbc62284b9f98059f0fd2657a1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data files: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82815d392a8d4d4f8697e201eeed1382"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Extracting data files: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cd30e05110e44a7ad2134eae6c0588b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Dataset imagefolder downloaded and prepared to /root/.cache/huggingface/datasets/imagefolder/default-bf4a63f19f0a675a/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n",
          "output_type": "stream"
        },
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['image', 'text'],\n    num_rows: 199\n})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict 16 images of Test Data from trained model\n",
        "fig = plt.figure(figsize=(18, 18))  # Increase the size of the figure to accommodate 4x4 subplots\n",
        "average_bleu = 0\n",
        "n = 15\n",
        "# # prepare image for the model\n",
        "for i, example in enumerate(test_dataset):\n",
        "     image = example[\"image\"]\n",
        "     inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
        "     pixel_values = inputs.pixel_values\n",
        "\n",
        "     generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n",
        "     generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "     fig.add_subplot(4, 4, i+1)  # Change the size of the grid to 4x4\n",
        "     plt.imshow(image)\n",
        "     plt.axis(\"off\")\n",
        "     plt.title(f\"Generated caption: {generated_caption}\")\n",
        "     average_bleu += sentence_bleu([example['text']] , generated_caption.split())\n",
        "\n",
        "     if i == n:  # Display 199 images\n",
        "         break\n",
        "print(\"Average BLEU: \" , average_bleu/n)\n",
        "plt.show()  # Show the plot after all subplots are added"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T09:00:58.734507Z",
          "iopub.execute_input": "2023-08-28T09:00:58.735117Z",
          "iopub.status.idle": "2023-08-28T09:00:58.740337Z",
          "shell.execute_reply.started": "2023-08-28T09:00:58.735083Z",
          "shell.execute_reply": "2023-08-28T09:00:58.739230Z"
        },
        "trusted": true,
        "id": "V2GvVb9bdrQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy Model with Gradio:"
      ],
      "metadata": {
        "id": "z8UmiR-IdrQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T09:00:58.741826Z",
          "iopub.execute_input": "2023-08-28T09:00:58.743063Z",
          "iopub.status.idle": "2023-08-28T09:01:19.279518Z",
          "shell.execute_reply.started": "2023-08-28T09:00:58.743028Z",
          "shell.execute_reply": "2023-08-28T09:01:19.278310Z"
        },
        "trusted": true,
        "id": "JZGXNMfHdrQl",
        "outputId": "4d8d17b9-3f5b-4c9a-8136-8215c43607ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from PIL import Image"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T09:01:19.283370Z",
          "iopub.execute_input": "2023-08-28T09:01:19.283695Z",
          "iopub.status.idle": "2023-08-28T09:01:20.981840Z",
          "shell.execute_reply.started": "2023-08-28T09:01:19.283663Z",
          "shell.execute_reply": "2023-08-28T09:01:20.980801Z"
        },
        "trusted": true,
        "id": "QPH6Akx5drQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = AutoProcessor.from_pretrained(saved_folder_path)\n",
        "model = BlipForConditionalGeneration.from_pretrained(saved_folder_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T09:01:20.983107Z",
          "iopub.execute_input": "2023-08-28T09:01:20.984098Z",
          "iopub.status.idle": "2023-08-28T09:01:24.127067Z",
          "shell.execute_reply.started": "2023-08-28T09:01:20.984061Z",
          "shell.execute_reply": "2023-08-28T09:01:24.125764Z"
        },
        "trusted": true,
        "id": "Otn5QWgxdrQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prediction function\n",
        "def generate_caption(image):\n",
        "    # Process the image\n",
        "    image = Image.fromarray(image)\n",
        "    #inputs = tokenizer(image, return_tensors=\"pt\")\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")#.to(device)\n",
        "    pixel_values = inputs.pixel_values\n",
        "\n",
        "    # Generate caption\n",
        "    generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n",
        "    generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "    return generated_caption"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T09:01:24.128644Z",
          "iopub.execute_input": "2023-08-28T09:01:24.129168Z",
          "iopub.status.idle": "2023-08-28T09:01:24.139246Z",
          "shell.execute_reply.started": "2023-08-28T09:01:24.129124Z",
          "shell.execute_reply": "2023-08-28T09:01:24.135696Z"
        },
        "trusted": true,
        "id": "pvYcqlladrQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=generate_caption,\n",
        "    inputs=gr.Image(),\n",
        "    outputs=gr.Textbox(),\n",
        "    live=True\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T09:01:24.140713Z",
          "iopub.execute_input": "2023-08-28T09:01:24.141736Z",
          "iopub.status.idle": "2023-08-28T09:01:24.264194Z",
          "shell.execute_reply.started": "2023-08-28T09:01:24.141697Z",
          "shell.execute_reply": "2023-08-28T09:01:24.263255Z"
        },
        "trusted": true,
        "id": "e1Nhd0dudrQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch the Gradio interface\n",
        "interface.launch()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T09:01:24.269360Z",
          "iopub.execute_input": "2023-08-28T09:01:24.269656Z",
          "iopub.status.idle": "2023-08-28T09:01:29.489012Z",
          "shell.execute_reply.started": "2023-08-28T09:01:24.269629Z",
          "shell.execute_reply": "2023-08-28T09:01:29.488085Z"
        },
        "trusted": true,
        "id": "3Zh_FbladrQp",
        "outputId": "933daa3f-cb36-4c87-ea49-85a5f4634a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Running on local URL:  http://127.0.0.1:7860\nKaggle notebooks require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\nRunning on public URL: https://7eed814e4efec5a6b3.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<div><iframe src=\"https://7eed814e4efec5a6b3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
          },
          "metadata": {}
        },
        {
          "execution_count": 28,
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Thanks\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-28T09:01:29.492047Z",
          "iopub.execute_input": "2023-08-28T09:01:29.492723Z",
          "iopub.status.idle": "2023-08-28T09:01:29.499443Z",
          "shell.execute_reply.started": "2023-08-28T09:01:29.492686Z",
          "shell.execute_reply": "2023-08-28T09:01:29.497253Z"
        },
        "trusted": true,
        "id": "bRFGspAZdrQp",
        "outputId": "3e4d8706-2935-43c4-dba6-f1c555b54f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Thanks\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "US_o_97udrQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TF_GcXR7drQq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}